{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db03b50",
   "metadata": {},
   "source": [
    "Vamos fazer a mesma coisa que foi feito em enem.ipynb porem com melhorias substanciais, pois foi tido um resultado ruim se levado em conta o potencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9aa634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em TP_ESCOLA: ['Publica' 'Privada']\n",
      "\n",
      "Colunas disponíveis no DataFrame: ['NU_INSCRICAO', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ESCOLA', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_LINGUA', 'NU_IDADE', 'NOTA_MEDIA', 'ESCOLA_PRIVADA', 'ESCOLA_PUBLICA', 'REGIAO_ESC']\n",
      "\n",
      "Colunas categóricas que serão usadas: ['TP_COR_RACA', 'TP_ESTADO_CIVIL', 'TP_SEXO', 'TP_NACIONALIDADE', 'TP_LINGUA', 'REGIAO_ESC', 'TP_NACIONALIDADE']\n",
      "\n",
      "Erro durante o pré-processamento:\n",
      "A given column is not a column of the dataframe\n",
      "\n",
      "Verifique os tipos de dados das colunas:\n",
      "TP_COR_RACA                     object\n",
      "NU_IDADE                       float64\n",
      "ESCOLA_PRIVADA                   int64\n",
      "ESCOLA_PUBLICA                   int64\n",
      "REGIAO_ESC                      object\n",
      "NUM_SEXO                       float64\n",
      "BIN_REGIAO_Norte                 int64\n",
      "BIN_REGIAO_Nordeste              int64\n",
      "BIN_REGIAO_Centro-Oeste          int64\n",
      "BIN_REGIAO_Sudeste               int64\n",
      "BIN_REGIAO_Sul                   int64\n",
      "ESTADO_CIVIL_Solteiro(a)         int64\n",
      "ESTADO_CIVIL_Nao informado       int64\n",
      "ESTADO_CIVIL_Divordicado(a)      int64\n",
      "ESTADO_CIVIL_Casado(a)           int64\n",
      "ESTADO_CIVIL_Viuvo(a)            int64\n",
      "LINGUA_INGLES                    int64\n",
      "BRASILEIRO                       int64\n",
      "N_BRASILEIRO                     int64\n",
      "dtype: object\n",
      "As seguinte features serao utilizadas: ['TP_COR_RACA', 'NU_IDADE', 'NOTA_MEDIA', 'ESCOLA_PRIVADA', 'ESCOLA_PUBLICA', 'REGIAO_ESC', 'NUM_SEXO', 'BIN_REGIAO_Norte', 'BIN_REGIAO_Nordeste', 'BIN_REGIAO_Centro-Oeste', 'BIN_REGIAO_Sudeste', 'BIN_REGIAO_Sul', 'ESTADO_CIVIL_Solteiro(a)', 'ESTADO_CIVIL_Nao informado', 'ESTADO_CIVIL_Divordicado(a)', 'ESTADO_CIVIL_Casado(a)', 'ESTADO_CIVIL_Viuvo(a)', 'LINGUA_INGLES', 'BRASILEIRO', 'N_BRASILEIRO']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv(\"../../Data/dados_enem_2022_limpo.csv\")\n",
    "\n",
    "# Remover colunas de notas (já temos NOTA_MEDIA)\n",
    "df = df.drop(['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'], axis=1)\n",
    "\n",
    "# Verificar valores da coluna TP_ESCOLA\n",
    "print(\"Valores únicos em TP_ESCOLA:\", df['TP_ESCOLA'].unique())\n",
    "\n",
    "# Criar colunas dummy para tipo de escola\n",
    "df['ESCOLA_PRIVADA'] = (df['TP_ESCOLA'] == 'Privada').astype(int)\n",
    "df['ESCOLA_PUBLICA'] = (df['TP_ESCOLA'] == 'Publica').astype(int)\n",
    "\n",
    "# Criar coluna REGIAO_ESC apenas se SG_UF_ESC existir\n",
    "if 'SG_UF_ESC' in df.columns:\n",
    "    uf_para_regiao = {\n",
    "        # Norte\n",
    "        'AC': 'Norte', 'AP': 'Norte', 'AM': 'Norte', 'PA': 'Norte', \n",
    "        'RO': 'Norte', 'RR': 'Norte', 'TO': 'Norte',\n",
    "        # Nordeste\n",
    "        'AL': 'Nordeste', 'BA': 'Nordeste', 'CE': 'Nordeste', 'MA': 'Nordeste', \n",
    "        'PB': 'Nordeste', 'PE': 'Nordeste', 'PI': 'Nordeste', 'RN': 'Nordeste', 'SE': 'Nordeste',\n",
    "        # Centro-Oeste\n",
    "        'DF': 'Centro-Oeste', 'GO': 'Centro-Oeste', 'MT': 'Centro-Oeste', 'MS': 'Centro-Oeste',\n",
    "        # Sudeste\n",
    "        'ES': 'Sudeste', 'MG': 'Sudeste', 'RJ': 'Sudeste', 'SP': 'Sudeste',\n",
    "        # Sul\n",
    "        'PR': 'Sul', 'RS': 'Sul', 'SC': 'Sul'\n",
    "    }\n",
    "    df['REGIAO_ESC'] = df['SG_UF_ESC'].map(uf_para_regiao)\n",
    "\n",
    "# Transformação de features numéricas\n",
    "df['NOTA_MEDIA'] = df['NOTA_MEDIA'] / 1000\n",
    "idade_max = df['NU_IDADE'].max()\n",
    "idade = 100\n",
    "if idade_max > 100:\n",
    "    print(\"Erro: Idade maxima {} passa do limite {} para atributo idade!\".format(idade_max, idade))\n",
    "df['NU_IDADE'] = df['NU_IDADE'] / idade\n",
    "\n",
    "# Verificar colunas disponíveis antes do ColumnTransformer\n",
    "print(\"\\nColunas disponíveis no DataFrame:\", df.columns.tolist())\n",
    "\n",
    "# Codificação de features categóricas\n",
    "# Verificar quais colunas categóricas realmente existem e são relevantes\n",
    "available_categorical = []\n",
    "for col in ['TP_COR_RACA', 'TP_ESTADO_CIVIL', 'TP_SEXO', 'TP_NACIONALIDADE', 'TP_LINGUA', 'REGIAO_ESC', 'TP_NACIONALIDADE']:\n",
    "    if col in df.columns:\n",
    "        available_categorical.append(col)\n",
    "    else:\n",
    "        print(f\"Aviso: Coluna {col} não encontrada no DataFrame\")\n",
    "\n",
    "features_dropadas = ['NU_INSCRICAO', 'TP_ESCOLA', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC']\n",
    "df = df.drop(features_dropadas, axis=1)\n",
    "\n",
    "print(\"\\nColunas categóricas que serão usadas:\", available_categorical)\n",
    "\n",
    "# Identificar colunas numéricas que devem ser mantidas\n",
    "numeric_features = ['ESCOLA_PRIVADA', 'ESCOLA_PUBLICA', 'NU_IDADE', 'NOTA_MEDIA']\n",
    "numeric_features = [col for col in numeric_features if col in df.columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), available_categorical)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Transformar features categoricas em numéricas\n",
    "df['NUM_SEXO'] = df['TP_SEXO'].map({'Feminino': 0, 'Masculino': 1})\n",
    "\n",
    "regioes = ['Norte', 'Nordeste', 'Centro-Oeste', 'Sudeste', 'Sul']\n",
    "for regiao in regioes:\n",
    "    df[f'BIN_REGIAO_{regiao}'] = (df['REGIAO_ESC'] == regiao).astype(int)\n",
    "\n",
    "estados_civis = df['TP_ESTADO_CIVIL'].unique()\n",
    "for estado in estados_civis:\n",
    "    df[f'ESTADO_CIVIL_{estado}'] = (df['TP_ESTADO_CIVIL'] == estado).astype(int)\n",
    "\n",
    "df['LINGUA_INGLES'] = (df['TP_LINGUA'] == 'Inglês').astype(int)\n",
    "\n",
    "nacionalidades = df['TP_NACIONALIDADE'].unique()\n",
    "for nac in nacionalidades:\n",
    "    if (nac == 'Brasileiro(a)'):\n",
    "        df[f'BRASILEIRO'] = (df['TP_NACIONALIDADE'] == nac).astype(int)\n",
    "    else:\n",
    "        df[f'N_BRASILEIRO'] = (df['TP_NACIONALIDADE'] == nac).astype(int)\n",
    "\n",
    "# Dropar features a nao mais serem utilizadas\n",
    "features_dropadas = ['TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_NACIONALIDADE', 'TP_LINGUA', 'TP_COR_RACA']\n",
    "df = df.drop(features_dropadas, axis=1)\n",
    "\n",
    "# Separar features e target\n",
    "X = df.drop('NOTA_MEDIA', axis=1)\n",
    "y = df['NOTA_MEDIA'].values\n",
    "\n",
    "print(\"As seguinte features serao utilizadas: {}\".format(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48a7414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>NOTA_MEDIA</th>\n",
       "      <th>ESCOLA_PRIVADA</th>\n",
       "      <th>ESCOLA_PUBLICA</th>\n",
       "      <th>REGIAO_ESC</th>\n",
       "      <th>NUM_SEXO</th>\n",
       "      <th>BIN_REGIAO_Norte</th>\n",
       "      <th>BIN_REGIAO_Nordeste</th>\n",
       "      <th>BIN_REGIAO_Centro-Oeste</th>\n",
       "      <th>BIN_REGIAO_Sudeste</th>\n",
       "      <th>BIN_REGIAO_Sul</th>\n",
       "      <th>ESTADO_CIVIL_Solteiro(a)</th>\n",
       "      <th>ESTADO_CIVIL_Nao informado</th>\n",
       "      <th>ESTADO_CIVIL_Divordicado(a)</th>\n",
       "      <th>ESTADO_CIVIL_Casado(a)</th>\n",
       "      <th>ESTADO_CIVIL_Viuvo(a)</th>\n",
       "      <th>LINGUA_INGLES</th>\n",
       "      <th>BRASILEIRO</th>\n",
       "      <th>N_BRASILEIRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parda</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.47194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Branca</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.79354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sudeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parda</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.57924</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Centro-Oeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parda</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.46996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Branca</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.48966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sudeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191308</th>\n",
       "      <td>Parda</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.60774</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191309</th>\n",
       "      <td>Parda</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.49778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191310</th>\n",
       "      <td>Preta</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.54680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191311</th>\n",
       "      <td>Parda</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.47994</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191312</th>\n",
       "      <td>Branca</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.54014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191313 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TP_COR_RACA  NU_IDADE  NOTA_MEDIA  ESCOLA_PRIVADA  ESCOLA_PUBLICA  \\\n",
       "0            Parda      0.20     0.47194               0               1   \n",
       "1           Branca      0.18     0.79354               0               1   \n",
       "2            Parda      0.17     0.57924               0               1   \n",
       "3            Parda      0.18     0.46996               0               1   \n",
       "4           Branca      0.18     0.48966               0               1   \n",
       "...            ...       ...         ...             ...             ...   \n",
       "191308       Parda      0.18     0.60774               0               1   \n",
       "191309       Parda      0.17     0.49778               0               1   \n",
       "191310       Preta      0.18     0.54680               0               1   \n",
       "191311       Parda      0.18     0.47994               0               1   \n",
       "191312      Branca      0.17     0.54014               0               1   \n",
       "\n",
       "          REGIAO_ESC  NUM_SEXO  BIN_REGIAO_Norte  BIN_REGIAO_Nordeste  \\\n",
       "0           Nordeste       NaN                 0                    1   \n",
       "1            Sudeste       NaN                 0                    0   \n",
       "2       Centro-Oeste       NaN                 0                    0   \n",
       "3              Norte       NaN                 1                    0   \n",
       "4            Sudeste       NaN                 0                    0   \n",
       "...              ...       ...               ...                  ...   \n",
       "191308      Nordeste       NaN                 0                    1   \n",
       "191309      Nordeste       NaN                 0                    1   \n",
       "191310      Nordeste       NaN                 0                    1   \n",
       "191311      Nordeste       NaN                 0                    1   \n",
       "191312      Nordeste       NaN                 0                    1   \n",
       "\n",
       "        BIN_REGIAO_Centro-Oeste  BIN_REGIAO_Sudeste  BIN_REGIAO_Sul  \\\n",
       "0                             0                   0               0   \n",
       "1                             0                   1               0   \n",
       "2                             1                   0               0   \n",
       "3                             0                   0               0   \n",
       "4                             0                   1               0   \n",
       "...                         ...                 ...             ...   \n",
       "191308                        0                   0               0   \n",
       "191309                        0                   0               0   \n",
       "191310                        0                   0               0   \n",
       "191311                        0                   0               0   \n",
       "191312                        0                   0               0   \n",
       "\n",
       "        ESTADO_CIVIL_Solteiro(a)  ESTADO_CIVIL_Nao informado  \\\n",
       "0                              1                           0   \n",
       "1                              1                           0   \n",
       "2                              1                           0   \n",
       "3                              1                           0   \n",
       "4                              1                           0   \n",
       "...                          ...                         ...   \n",
       "191308                         1                           0   \n",
       "191309                         1                           0   \n",
       "191310                         1                           0   \n",
       "191311                         1                           0   \n",
       "191312                         1                           0   \n",
       "\n",
       "        ESTADO_CIVIL_Divordicado(a)  ESTADO_CIVIL_Casado(a)  \\\n",
       "0                                 0                       0   \n",
       "1                                 0                       0   \n",
       "2                                 0                       0   \n",
       "3                                 0                       0   \n",
       "4                                 0                       0   \n",
       "...                             ...                     ...   \n",
       "191308                            0                       0   \n",
       "191309                            0                       0   \n",
       "191310                            0                       0   \n",
       "191311                            0                       0   \n",
       "191312                            0                       0   \n",
       "\n",
       "        ESTADO_CIVIL_Viuvo(a)  LINGUA_INGLES  BRASILEIRO  N_BRASILEIRO  \n",
       "0                           0              0           1             0  \n",
       "1                           0              0           1             0  \n",
       "2                           0              0           1             0  \n",
       "3                           0              0           1             0  \n",
       "4                           0              0           1             0  \n",
       "...                       ...            ...         ...           ...  \n",
       "191308                      0              0           1             0  \n",
       "191309                      0              0           1             0  \n",
       "191310                      0              0           1             0  \n",
       "191311                      0              0           1             0  \n",
       "191312                      0              0           1             0  \n",
       "\n",
       "[191313 rows x 20 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95061d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class EnhancedENEMRegressor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "        # Inicialização cuidadosa\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9620cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Divisão dos dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converter para tensores\n",
    "X_train_tensor = torch.FloatTensor(X_train.toarray() if hasattr(X_train, 'toarray') else X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test.toarray() if hasattr(X_test, 'toarray') else X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "# Criar DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Configuração do treino\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EnhancedENEMRegressor(X_train.shape[1]).to(device)\n",
    "\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, \n",
    "                                        steps_per_epoch=len(train_loader), \n",
    "                                        epochs=50)\n",
    "\n",
    "# Monitoramento com TensorBoard\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validação\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            \n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Métricas\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(test_loader)\n",
    "    r2 = r2_score(np.concatenate(all_labels), np.concatenate(all_preds))\n",
    "    \n",
    "    # Log no TensorBoard\n",
    "    writer.add_scalars('Loss', {'train': train_loss, 'val': val_loss}, epoch)\n",
    "    writer.add_scalar('R2', r2, epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch+1:02d} | '\n",
    "          f'Train Loss: {train_loss:.4f} | '\n",
    "          f'Val Loss: {val_loss:.4f} | '\n",
    "          f'R²: {r2:.4f} | '\n",
    "          f'LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47cbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Função para plotar resultados\n",
    "def plot_results(model, X_test_tensor, y_test_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor.to(device)).cpu().numpy()\n",
    "        actuals = y_test_tensor.numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Gráfico de dispersão\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(actuals, predictions, alpha=0.3)\n",
    "    plt.plot([actuals.min(), actuals.max()], [actuals.min(), actuals.max()], 'r--')\n",
    "    plt.xlabel('Valores Reais')\n",
    "    plt.ylabel('Predições')\n",
    "    plt.title(f'R²: {r2_score(actuals, predictions):.4f}')\n",
    "    \n",
    "    # Distribuição de erros\n",
    "    plt.subplot(1, 2, 2)\n",
    "    errors = predictions.flatten() - actuals.flatten()\n",
    "    plt.hist(errors, bins=50)\n",
    "    plt.xlabel('Erros de Predição')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.title(f'MSE: {mean_squared_error(actuals, predictions):.4f}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(model, X_test_tensor, y_test_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
